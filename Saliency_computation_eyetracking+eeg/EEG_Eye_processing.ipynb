{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file will syncronise with eye tracking data to create event markers first. Then it will clean and process eeg raw data in proper data format. It will then be clustered and labelled into 3 states :{ Attention, Neutral, Rejection } . Then, It will re-syncronise with the eye tracking data to create a new eye tracking with labels which would contain both eye tracking and eeg labels. Afterwhich, It runs a processing method to compute saliency for attention and preference based on the eeg and eye tracking data. The points with the saliency score is the hitpoint data. Additional steps will be required to impose hitpoint saliency onto mesh points. The output file will ultimately be Point Cloud with saliency scores.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#install dependencies\n",
    "!pip install autoreject\n",
    "!pip install mne\n",
    "!pip install pyedflib\n",
    "!pip install --upgrade mne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below concatenates easy files if required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Concatenate eeg files if needed, otherwise skip this step \n",
    "import pandas as pd\n",
    "\n",
    "# Paths to your .easy files\n",
    "file1 = \"\"\n",
    "file2 = \"\"\n",
    "\n",
    "# Load both files into pandas DataFrames\n",
    "try:\n",
    "    df1 = pd.read_csv(file1, sep='\\t', header=None)  # Adjust header if the files have headers\n",
    "    df2 = pd.read_csv(file2, sep='\\t', header=None)\n",
    "\n",
    "    combined_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "   \n",
    "    print(\"Files combined successfully. Here's a preview:\")\n",
    "    print(combined_df.head())  \n",
    "    print(\"Last few rows of the combined DataFrame:\")\n",
    "    print(combined_df.tail()) \n",
    "except Exception as e:\n",
    "    print(f\"Error combining files: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below syncs eye tracking and eeg files to mark events on the eeg file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "file_path = \"\" ## eeg file \n",
    "data = pd.read_csv(file_path, delimiter=\"\\t\", dtype={'column_name': 'category', 'another_column': 'float64'})\n",
    "\n",
    "num_columns = data.shape[1]\n",
    "headers = [f'channel {i+1}' for i in range(num_columns - 5)] + ['aX', 'aY', 'aZ','markers', 'timestamp']\n",
    "\n",
    "data.columns = headers\n",
    "data['timestamp'] = pd.to_datetime(data['timestamp'], unit='ms')\n",
    "\n",
    "data['timestamp'] = pd.to_datetime(data['timestamp'], format='%d/%m/%Y %I:%M:%S %p')\n",
    "#scaling factor as eeg raw data is in nanovolts but processing of eeg is in microvolts\n",
    "scaling_factor = 1e-3\n",
    "\n",
    "eeg_channels = [col for col in data.columns if 'channel' in col]\n",
    "for col in eeg_channels:\n",
    "    data[col] = data[col] * scaling_factor\n",
    "output_csv_path = \"output_data.csv\"\n",
    "data.to_csv(output_csv_path, index=False)\n",
    "print(f\"Data saved to {output_csv_path}\")\n",
    "eeg_data = data\n",
    "eeg_data['timestamp'] = pd.to_datetime(eeg_data['timestamp'])\n",
    "eeg_data['markers'] = 0\n",
    "\n",
    "for n in range(1, 16):  \n",
    "    for shape in ['curved', 'rect']:\n",
    "        eye_file = f\"/eyetrackingdata__{shape}{n}.csv\" ##csv for eye tracking to sync timestamp \n",
    "        try:\n",
    "            eye_data = pd.read_csv(eye_file)\n",
    "            eye_data['Timestamp'] = pd.to_datetime(eye_data['Timestamp'], errors='coerce')\n",
    "            eye_data = eye_data.drop_duplicates().sort_values(by='Timestamp').reset_index(drop=True)\n",
    "            eye_data['Timestamp'] -= timedelta(hours=8)  # Adjust timezone\n",
    "\n",
    "            eeg_timestamps = eeg_data['timestamp'].to_numpy()\n",
    "            eye_timestamps = eye_data['Timestamp'].to_numpy()\n",
    "\n",
    "            closest_indices = np.searchsorted(eeg_timestamps, eye_timestamps)\n",
    "            closest_indices = np.clip(closest_indices, 1, len(eeg_timestamps) - 1)\n",
    "            left_diffs = np.abs(eeg_timestamps[closest_indices - 1] - eye_timestamps)\n",
    "            right_diffs = np.abs(eeg_timestamps[closest_indices] - eye_timestamps)\n",
    "\n",
    "            best_indices = np.where(left_diffs <= right_diffs, closest_indices - 1, closest_indices)\n",
    "\n",
    "            eeg_data.loc[best_indices, 'markers'] = 1\n",
    "\n",
    "            print(f\"Processed and synced file: {eye_file}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {eye_file}: {e}\")\n",
    "\n",
    "# please do not use this file for processing as excel has limited rows so some data is lost in this file. Use the stored dataframe instance. This file is only used for visual purpose. \n",
    "output_file = \"compiled_synced_eeg_data.csv\"\n",
    "eeg_data.to_csv(output_file, index=False)\n",
    "print(f\"Final synchronized EEG data saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below checks if it is properly synced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "total_rows = 0\n",
    "\n",
    "for n in range(1, 16):  \n",
    "    for shape in ['curved', 'rect']:\n",
    "        eye_file = f\"/eyetrackingdata__{shape}{n}.csv\"\n",
    "\n",
    "        try:\n",
    "            eye_data = pd.read_csv(eye_file)\n",
    "            total_rows += len(eye_data)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {eye_file}: {e}\")\n",
    "\n",
    "print(f\"Total number of rows across all eye-tracking files: {total_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Count the number of rows where markers == 1\n",
    "num_markers = (eeg_data['markers'] == 1).sum()\n",
    "\n",
    "print(f\"Number of markers set to 1: {num_markers}\")\n",
    "print(eeg_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below looks at the visualisation of eeg signals after processing methods like filtering and ica removal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## visualisation of eeg signals after processing. Check the efficacy of filtering and cleaning methods\n",
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sfreq = 256  # Sampling frequency\n",
    "eeg_channels = [\"channel 1\", \"channel 2\", \"channel 7\", \"channel 8\"]  # EEG channels\n",
    "ch_names = eeg_channels + [\"markers\"]\n",
    "ch_types = [\"eeg\"] * len(eeg_channels) + [\"stim\"]\n",
    "\n",
    "# Extract and transpose data\n",
    "raw_data = data[eeg_channels + [\"markers\"]].to_numpy().T\n",
    "\n",
    "# Create MNE RawArray\n",
    "info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types=ch_types)\n",
    "raw = mne.io.RawArray(raw_data, info)\n",
    "\n",
    "mapping = {\n",
    "    \"channel 1\": \"F7\",\n",
    "    \"channel 2\": \"AF7\",\n",
    "    \"channel 7\": \"AF8\",\n",
    "    \"channel 8\": \"F8\"\n",
    "}\n",
    "raw.rename_channels(mapping)\n",
    "\n",
    "montage = mne.channels.make_standard_montage(\"standard_1020\")\n",
    "raw.set_montage(montage)\n",
    "\n",
    "raw.filter(0.2, 35, fir_design=\"firwin\") \n",
    "raw.notch_filter(freqs=50, method=\"spectrum_fit\")  \n",
    "\n",
    "# Perform ICA for EOG artifact removal\n",
    "ica = mne.preprocessing.ICA(n_components=4, random_state=97, max_iter=800)\n",
    "ica.fit(raw)\n",
    "\n",
    "# Plot ICA components to visually inspect which component corresponds to EOG artifact\n",
    "ica.plot_components()\n",
    "\n",
    "# Assuming 'eog_inds' are indices of ICA components corresponding to EOG artifacts\n",
    "eog_inds, scores = ica.find_bads_eog(raw, ch_name=\"AF8\")  # Use relevant channel to find EOG components\n",
    "\n",
    "print(\"Identified EOG components:\", eog_inds)\n",
    "\n",
    "# Remove EOG artifacts by excluding the identified components\n",
    "ica.exclude = eog_inds\n",
    "raw_clean = ica.apply(raw)  # Apply ICA to remove artifacts\n",
    "\n",
    "# Plot the EEG data before and after ICA cleaning (using ICA overlay)\n",
    "ica.plot_overlay(raw, exclude=[0], picks=\"eeg\", title=\"Before and After ICA Cleaning\")\n",
    "\n",
    "\n",
    "# Show the plot with the legend\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below incoporates filtering, clustering and labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## Using Kmeans and Event Related Potential processing to cluster and label eeg signal points \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to extract band power\n",
    "def extract_band_power(psd_data, freqs, band):\n",
    "    band_indices = np.logical_and(freqs >= band[0], freqs <= band[1])\n",
    "    return psd_data[:, :, band_indices].mean(axis=2)\n",
    "\n",
    "data = eeg_data\n",
    "data[\"timestamp\"] = pd.to_datetime(data[\"timestamp\"], errors=\"coerce\")\n",
    "data.dropna(subset=[\"timestamp\"], inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Metadata\n",
    "sfreq = 256\n",
    "eeg_channels = [\"channel 1\", \"channel 2\", \"channel 7\", \"channel 8\"]\n",
    "ch_names = eeg_channels + [\"markers\"]\n",
    "ch_types = [\"eeg\"] * len(eeg_channels) + [\"stim\"]\n",
    "\n",
    "raw_data = data[eeg_channels + [\"markers\"]].to_numpy().T\n",
    "\n",
    "# Create MNE RawArray\n",
    "info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types=ch_types)\n",
    "raw = mne.io.RawArray(raw_data, info)\n",
    "\n",
    "# Map channel names to standard 10-20 system\n",
    "mapping = {\n",
    "    \"channel 1\": \"F7\",\n",
    "    \"channel 2\": \"AF7\",\n",
    "    \"channel 7\": \"AF8\",\n",
    "    \"channel 8\": \"F8\"\n",
    "}\n",
    "raw.rename_channels(mapping)\n",
    "\n",
    "montage = mne.channels.make_standard_montage(\"standard_1020\")\n",
    "raw.set_montage(montage)\n",
    "## If possible use xdawn filtering for ERP \n",
    "raw.filter(0.2, 35, fir_design=\"firwin\")  \n",
    "raw.notch_filter(freqs=50, method=\"spectrum_fit\") \n",
    "\n",
    "\n",
    "ica = mne.preprocessing.ICA(n_components=4, random_state=97, max_iter=800)\n",
    "ica.fit(raw)\n",
    "\n",
    "ica.plot_components()\n",
    "\n",
    "eog_indices, scores = ica.find_bads_eog(raw, ch_name=\"AF7\")\n",
    "\n",
    "# Exclude the identified EOG components\n",
    "ica.exclude = eog_indices\n",
    "\n",
    "# Apply ICA to remove the artifacts\n",
    "## If possible, use auto reject or channels with EOG for better removal of artifacts and noises\n",
    "raw_clean = ica.apply(raw)\n",
    "\n",
    "# Create events from cleaned raw data\n",
    "valid_markers = data[\"markers\"] == 1  \n",
    "if valid_markers.any():\n",
    "    events = np.array([[i, 0, 1] for i in range(len(data)) if valid_markers.iloc[i]])\n",
    "    event_id = {\"Event_1\": 1}\n",
    "\n",
    "    # Create epochs\n",
    "    epochs = mne.Epochs(\n",
    "        raw_clean, events, event_id=event_id, tmin=-0.2, tmax=0.9, preload=True\n",
    "    )\n",
    "\n",
    "    # Compute PSD for the epochs\n",
    "    spectrum = epochs.compute_psd(\n",
    "        method=\"welch\", fmin=0.5, fmax=40, n_fft=128\n",
    "    )\n",
    "    psd_data, freqs = spectrum.get_data(return_freqs=True)\n",
    "\n",
    "    # Feature extraction: P300 (Attention), N400 (Rejection), and LPP (Neutral)\n",
    "    p300_band = (10, 20)  # Attention\n",
    "    n400_band = (3, 6)   # Rejection\n",
    "    lpp_band = (1, 3)    # Neutral\n",
    "    \n",
    "    p300_amplitude = extract_band_power(psd_data, freqs, p300_band)\n",
    "    n400_amplitude = extract_band_power(psd_data, freqs, n400_band)\n",
    "    lpp_amplitude = extract_band_power(psd_data, freqs, lpp_band)\n",
    "\n",
    "    # Stack features for clustering\n",
    "    features = np.vstack((p300_amplitude.mean(axis=1), n400_amplitude.mean(axis=1), lpp_amplitude.mean(axis=1))).T\n",
    "\n",
    "    # KMeans clustering\n",
    "    kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(features)\n",
    "\n",
    "    # Compute silhouette score\n",
    "    silhouette_avg = silhouette_score(features, cluster_labels)\n",
    "    print(f\"Silhouette Score: {silhouette_avg}\")\n",
    "\n",
    "    # Map clusters to emotional states\n",
    "    cluster_map = {\n",
    "        0: 'Attention',     # High P300\n",
    "        1: 'Rejection',     # High N400\n",
    "        2: 'Neutral'        # High LPP\n",
    "    }\n",
    "\n",
    "    epoch_labels = [cluster_map[label] for label in cluster_labels]\n",
    "\n",
    "    data[\"label\"] = \"Neutral\"  \n",
    "    for i, label in enumerate(epoch_labels):\n",
    "        epoch_start = events[i, 0] \n",
    "        data.at[epoch_start, \"label\"] = label\n",
    "\n",
    "    output_path = \"labeled_eeg_data.csv\"\n",
    "    data.to_csv(output_path, index=False)\n",
    "    print(f\"Labeled data saved to {output_path}\")\n",
    "\n",
    "else:\n",
    "    print(\"No valid markers found.\")\n",
    "\n",
    "label_counts = data[\"label\"].value_counts()\n",
    "print(\"Summary of classifications:\")\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"{label}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below maps back eeg with labels with eye tracking data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "##Re sync the eeg events with eye tracking on a new file eye tracking with labels\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "\n",
    "eeg_data = data\n",
    "eeg_data['timestamp'] = pd.to_datetime(eeg_data['timestamp'])\n",
    "\n",
    "eeg_data['label'] = eeg_data['label'].fillna('Neutral')  # Fill missing labels with 'Neutral'\n",
    "\n",
    "for n in range(1, 16):  ## range of ur file \n",
    "    for shape in ['curved', 'rect']:\n",
    "        eye_file = f\"/eyetrackingdata__{shape}{n}.csv\"\n",
    "\n",
    "        try:\n",
    "            eye_data = pd.read_csv(eye_file)\n",
    "\n",
    "            eye_data['Timestamp'] = pd.to_datetime(eye_data['Timestamp'], errors='coerce')\n",
    "            eye_data = eye_data.drop_duplicates().sort_values(by='Timestamp').reset_index(drop=True)\n",
    "\n",
    "            # Add 8 hours to adjust for local time (if needed)\n",
    "            eye_data['Timestamp'] = eye_data['Timestamp'] - timedelta(hours=8)\n",
    "\n",
    "            eeg_timestamps = eeg_data['timestamp'].to_numpy()\n",
    "            eye_timestamps = eye_data['Timestamp'].to_numpy()\n",
    "\n",
    "            closest_indices = np.searchsorted(eeg_timestamps, eye_timestamps)\n",
    "\n",
    "            closest_indices = np.clip(closest_indices, 1, len(eeg_timestamps) - 1)\n",
    "            left_diffs = np.abs(eeg_timestamps[closest_indices - 1] - eye_timestamps)\n",
    "            right_diffs = np.abs(eeg_timestamps[closest_indices] - eye_timestamps)\n",
    "\n",
    "            best_indices = np.where(left_diffs <= right_diffs, closest_indices - 1, closest_indices)\n",
    "\n",
    "            eye_data['label'] = eeg_data.loc[best_indices, 'label'].values\n",
    "\n",
    "            output_file = f\"eye_tracking_with_labels_{shape}{n}.csv\"\n",
    "            eye_data.to_csv(output_file, index=False)\n",
    "            print(f\"Processed and labeled file: {eye_file}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {eye_file}: {e}\")\n",
    "\n",
    "print(\"Labeling process complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below checks for if eeg is merged well with eye tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "total_rejection = 0\n",
    "total_attention = 0\n",
    "total_neutral = 0\n",
    "\n",
    "file_summary = []\n",
    "\n",
    "## Do a quick visualisation if files are sync correctly. The numbers should tally. \n",
    "for n in range(1, 16):  \n",
    "    for shape in ['curved', 'rect']:\n",
    "        output_file = f\"/eye_tracking_with_labels_{shape}{n}.csv\"\n",
    "        try:\n",
    "            labeled_eye_data = pd.read_csv(output_file)\n",
    "            label_counts = labeled_eye_data['label'].value_counts()\n",
    "\n",
    "            rejection_count = label_counts.get('Rejection', 0)\n",
    "            attention_count = label_counts.get('Attention', 0)\n",
    "            neutral_count = label_counts.get('Neutral', 0)\n",
    "\n",
    "            total_rejection += rejection_count\n",
    "            total_attention += attention_count\n",
    "            total_neutral += neutral_count\n",
    "\n",
    "            file_summary.append({\n",
    "                'File': output_file,\n",
    "                'Rejection': rejection_count,\n",
    "                'Attention': attention_count,\n",
    "                'Neutral': neutral_count\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file {output_file}: {e}\")\n",
    "\n",
    "summary_df = pd.DataFrame(file_summary)\n",
    "\n",
    "print(\"Per-File Label Counts:\")\n",
    "print(summary_df)\n",
    "\n",
    "print(\"\\nTotal Counts Across All Files:\")\n",
    "print(f\"Total Rejection: {total_rejection}\")\n",
    "print(f\"Total Attention: {total_attention}\")\n",
    "print(f\"Total Neutral: {total_neutral}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below incoporates eeg and eye tracking data with eye tracking labelled data to compute attention and preference saliency. It is then combined through Sum and Multiply combined scores and outputed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.widgets import CheckButtons\n",
    "\n",
    "############################################################################################################################################\n",
    "df1 = pd.read_csv(\"/eye_tracking_with_labels_{shape}{n}.csv\") ## files with eye tracking and eeg labels\n",
    "\n",
    "## mesh data\n",
    "df2 = pd.read_csv(\"/{shape}{n}_points.csv\") ## files with point cloud \n",
    "############################################################################################################################################\n",
    "x_min, x_max = df2['x'].min(), df2['x'].max()\n",
    "y_min, y_max = df2['y'].min(), df2['y'].max()\n",
    "z_min, z_max = df2['z'].min(), df2['z'].max()\n",
    "\n",
    "print(\"Mesh Points Boundaries:\")\n",
    "print(f\"X range: [{x_min:.4f}, {x_max:.4f}]\")\n",
    "print(f\"Y range: [{y_min:.4f}, {y_max:.4f}]\")\n",
    "print(f\"Z range: [{z_min:.4f}, {z_max:.4f}]\")\n",
    "\n",
    "filtered_df1 = df1[\n",
    "    (df1['HitPointX'] >= x_min) & (df1['HitPointX'] <= x_max) &\n",
    "    (df1['HitPointY'] >= y_min) & (df1['HitPointY'] <= y_max) &\n",
    "    (df1['HitPointZ'] >= z_min) & (df1['HitPointZ'] <= z_max) &\n",
    "    (df1['HitObject'] != 'None')\n",
    "\n",
    "]\n",
    "    \n",
    "\n",
    "print(f\"\\nOriginal raw data points: {len(df1)}\")\n",
    "print(f\"Points after filtering: {len(filtered_df1)}\")\n",
    "print(f\"Mesh points: {len(df2)}\")\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [15, 10]\n",
    "fig = plt.figure()\n",
    "plt.subplots_adjust(left=0.1, bottom=0.1, right=0.95, top=0.95)\n",
    "\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "raw_data_plot = ax.scatter(filtered_df1['HitPointX'],\n",
    "                          filtered_df1['HitPointY'],\n",
    "                          filtered_df1['HitPointZ'],\n",
    "                          c='blue', marker='o', label='Raw Data (filtered)',\n",
    "                          alpha=0.6, s=1)\n",
    "\n",
    "mesh_points_plot = ax.scatter(df2['x'], df2['y'], df2['z'],\n",
    "                            c='red', marker='^', label='Mesh points',\n",
    "                            alpha=0.6, s=5)\n",
    "\n",
    "\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "ax.set_title('All Points Visualization\\nFiltered Raw Data and Mesh Points')\n",
    "ax.grid(True)\n",
    "ax.view_init(elev=20, azim=45)\n",
    "\n",
    "ax_check = plt.axes([0.02, 0.05, 0.15, 0.10])\n",
    "check = CheckButtons(ax_check, ['Raw Data', 'Mesh Points'],\n",
    "                    [True, True])  # Both visible initially\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "eye_data = filtered_df1.copy()\n",
    "eye_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Convert Timestamp to datetime format\n",
    "eye_data['Timestamp'] = pd.to_datetime(eye_data['Timestamp'])\n",
    "eye_data = eye_data.sort_values(by='Timestamp')\n",
    "eye_data = eye_data.drop_duplicates(keep='first')\n",
    "# Check for any conversion issues\n",
    "eye_data.reset_index(drop=True, inplace=True)\n",
    "if eye_data['Timestamp'].isnull().any():\n",
    "    print(\"Some timestamps could not be converted. Check the data for invalid formats.\")\n",
    "\n",
    "\n",
    "mesh_data = df2.copy()\n",
    "\n",
    "def cluster_eye_data(eye_data, normal_tolerance=0.001):\n",
    "    for i in range(len(eye_data) - 1):\n",
    "        current_row = eye_data[i]\n",
    "        next_row = eye_data[i + 1]\n",
    "\n",
    "        # Check gaze normal difference between current row and next row\n",
    "        normal_diff_next = check_normal_difference(current_row['NormalX'], current_row['NormalY'], current_row['NormalZ'],\n",
    "                                                   next_row['NormalX'], next_row['NormalY'], next_row['NormalZ'],\n",
    "                                                   normal_tolerance)\n",
    "\n",
    "        # If gaze normals are similar, update the current row's hit point\n",
    "        if normal_diff_next:\n",
    "            current_row['HitPointX'] = next_row['HitPointX']\n",
    "            current_row['HitPointY'] = next_row['HitPointY']\n",
    "            current_row['HitPointZ'] = next_row['HitPointZ']\n",
    "\n",
    "    return eye_data\n",
    "\n",
    "\n",
    "def check_normal_difference(normal1_x, normal1_y, normal1_z, normal2_x, normal2_y, normal2_z, tolerance):\n",
    "    ##cluster neighbouring points for more concentrated data\n",
    "    diff_x = abs(normal1_x - normal2_x)\n",
    "    diff_y = abs(normal1_y - normal2_y)\n",
    "    diff_z = abs(normal1_z - normal2_z)\n",
    "\n",
    "    # If the difference in all components is less than or equal to the tolerance, return True\n",
    "    return diff_x <= tolerance and diff_y <= tolerance and diff_z <= tolerance\n",
    "\n",
    "def check_normal_difference(normal1_x, normal1_y, normal1_z, normal2_x, normal2_y, normal2_z, tolerance):\n",
    "    # Calculate the difference between the two gaze normals in each component\n",
    "    diff_x = abs(normal1_x - normal2_x)\n",
    "    diff_y = abs(normal1_y - normal2_y)\n",
    "    diff_z = abs(normal1_z - normal2_z)\n",
    "\n",
    "    # If the difference in all components is less than or equal to the tolerance, return True\n",
    "    return diff_x <= tolerance and diff_y <= tolerance and diff_z <= tolerance\n",
    "\n",
    "def calculate_eye_tracking_metrics(data, fixation_threshold=0.1):\n",
    "    metrics_list = []\n",
    "    visited_points = {}\n",
    "    data['InitialSaliency'] = 0\n",
    "\n",
    "    for i, row in data.iterrows():\n",
    "        current_point = (row['HitPointX'], row['HitPointY'], row['HitPointZ'])\n",
    "        timestamp = row['Timestamp']\n",
    "        label = row['label']\n",
    "\n",
    "        if current_point not in visited_points:\n",
    "            visited_points[current_point] = {\n",
    "                'FixationCount': 0,\n",
    "                'DwellTime': 0,  # Accumulate total dwell time for the point\n",
    "                'RevisitCount': 0,\n",
    "                'TTFF': None,  # Initialize Time to First Fixation as None\n",
    "                'CumulativeDwell': 0,  # Track cumulative dwell time for fixation threshold\n",
    "                'FirstFixationTime': None,  # To track when first fixation happens\n",
    "                'Labels': set()  # Store unique labels for this point\n",
    "            }\n",
    "\n",
    "        visited_points[current_point]['Labels'].add(label)\n",
    "\n",
    "        if i < len(data) - 1:\n",
    "            next_row = data.iloc[i + 1]\n",
    "            next_timestamp = next_row['Timestamp']\n",
    "            dwell_time = (next_timestamp - timestamp).total_seconds()\n",
    "            visited_points[current_point]['DwellTime'] += dwell_time\n",
    "\n",
    "            # Accumulate CumulativeDwell only if the current and next points are the same\n",
    "            next_point = (next_row['HitPointX'], next_row['HitPointY'], next_row['HitPointZ'])\n",
    "            if current_point == next_point:\n",
    "                visited_points[current_point]['CumulativeDwell'] += dwell_time\n",
    "            else:\n",
    "                # Reset CumulativeDwell if the current point does not match the next point\n",
    "                visited_points[current_point]['CumulativeDwell'] = 0\n",
    "\n",
    "        # Time to First Fixation (TTFF) logic: set only the first time the fixation threshold is exceeded\n",
    "        if visited_points[current_point]['FirstFixationTime'] is None and visited_points[current_point]['CumulativeDwell'] >= fixation_threshold:\n",
    "            visited_points[current_point]['FirstFixationTime'] = timestamp\n",
    "            visited_points[current_point]['TTFF'] = (timestamp - data['Timestamp'].min()).total_seconds()\n",
    "\n",
    "        # Fixation Count: Increment each time the cumulative dwell time exceeds the threshold\n",
    "        if visited_points[current_point]['CumulativeDwell'] >= fixation_threshold:\n",
    "            visited_points[current_point]['FixationCount'] += 1\n",
    "            visited_points[current_point]['CumulativeDwell'] = 0  \n",
    "\n",
    "        # Revisit Count: Increment when the same point appears consecutively in the data\n",
    "        if i > 0:\n",
    "            previous_point = (data.loc[i - 1, 'HitPointX'], data.loc[i - 1, 'HitPointY'], data.loc[i - 1, 'HitPointZ'])\n",
    "            if current_point == previous_point:\n",
    "                visited_points[current_point]['RevisitCount'] += 1\n",
    "\n",
    "    for point, metric in visited_points.items():\n",
    "        metrics_list.append({\n",
    "            'HitPointX': point[0],\n",
    "            'HitPointY': point[1],\n",
    "            'HitPointZ': point[2],\n",
    "            'FixationCount': metric['FixationCount'],\n",
    "            'DwellTime': metric['DwellTime'],\n",
    "            'RevisitCount': metric['RevisitCount'],\n",
    "            'TTFF': metric['TTFF'] if metric['TTFF'] is not None else 0,\n",
    "            'Labels': tuple(metric['Labels'])  # Convert the set to a tuple\n",
    "        })\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics_list)\n",
    "\n",
    "    # Normalize metrics with inverse normalization for TTFF\n",
    "    for col in ['FixationCount', 'DwellTime', 'RevisitCount']:\n",
    "        if metrics_df[col].max() != 0:  # Avoid division by zero\n",
    "            metrics_df[col] = metrics_df[col] / metrics_df[col].max()\n",
    "\n",
    "    # Inverse normalization for TTFF: lower TTFF is more salient\n",
    "    if metrics_df['TTFF'].min() != 0:\n",
    "        metrics_df['TTFF'] = 1 - (metrics_df['TTFF'] / metrics_df['TTFF'].max())\n",
    "    else:\n",
    "        metrics_df['TTFF'] = 0\n",
    "\n",
    "    metrics_df['InitialSaliency'] = (\n",
    "        0.1 +\n",
    "        0.2 * metrics_df['FixationCount'] +\n",
    "        0.3 * metrics_df['DwellTime'] +\n",
    "        0.2 * metrics_df['RevisitCount'] +\n",
    "        0.2 * metrics_df['TTFF']\n",
    "    )\n",
    "\n",
    "    metrics_df['RevisitCount'] = metrics_df['RevisitCount'].astype(int)\n",
    "\n",
    "    return metrics_df\n",
    "\n",
    "\n",
    "# Example usage assuming eye_data DataFrame has a 'EEGLabel' column\n",
    "eye_metrics = calculate_eye_tracking_metrics(eye_data)\n",
    "\n",
    "def normalize_saliency_score(data):\n",
    "    \"\"\"\n",
    "    Normalize the InitialSaliency score by dividing it by its maximum value.\n",
    "    The result will be a saliency score between 0 and 1.\n",
    "    \"\"\"\n",
    "    max_saliency = data['InitialSaliency'].max()\n",
    "\n",
    "    if max_saliency != 0:\n",
    "        data['InitialSaliency'] = data['InitialSaliency'] / max_saliency\n",
    "    else:\n",
    "        data['InitialSaliency'] = 0\n",
    "\n",
    "    return data\n",
    "eye_metrics = calculate_eye_tracking_metrics(eye_data)\n",
    "\n",
    "# Normalize the InitialSaliency score\n",
    "eye_metrics = normalize_saliency_score(eye_metrics)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "mesh_points = df2.copy()\n",
    "N = len(mesh_points)\n",
    "\n",
    "alpha = 0.5\n",
    "\n",
    "average_spacing = 1 / np.cbrt(N)\n",
    "\n",
    "# Calculate mesh volume based on x, y, and z ranges\n",
    "mesh_volume = (mesh_points['x'].max() - mesh_points['x'].min()) * \\\n",
    "              (mesh_points['y'].max() - mesh_points['y'].min()) * \\\n",
    "              (mesh_points['z'].max() - mesh_points['z'].min())\n",
    "\n",
    "# Calculate initial and adjusted radius based on mesh volume normalization\n",
    "radius = average_spacing * (alpha ** (1 / 3))\n",
    "adjusted_radius = radius * np.sqrt(mesh_volume / (N * (4 / 3) * np.pi * radius**3))\n",
    "\n",
    "print(f\"Adjusted Radius: {adjusted_radius}\")\n",
    "\n",
    "k = 0.4  # Weight for saliency scores\n",
    "\n",
    "# KDTree preparation for eye points and mesh points\n",
    "eye_points = eye_metrics[['HitPointX', 'HitPointY', 'HitPointZ']].values\n",
    "mesh_points_coords = mesh_points[['x', 'y', 'z']].values\n",
    "eye_tree = cKDTree(eye_points)\n",
    "\n",
    "# Initialize columns\n",
    "mesh_points['SaliencyScore'] = 0.0\n",
    "mesh_points['EEGScore'] = 0.0\n",
    "mesh_points['Labels'] = [[] for _ in range(len(mesh_points))]\n",
    "\n",
    "# Define label scores \n",
    "label_scores = {'Attention': 1, 'Rejection': -1, 'Neutral': 0}\n",
    "\n",
    "# Query the mesh points against the eye hit points (remove distance_upper_bound)\n",
    "distances, indices = eye_tree.query(mesh_points_coords, k=len(eye_points))  # Query all eye points for each mesh point\n",
    "\n",
    "# Process each mesh point to capture the valid neighbors within the adjusted radius\n",
    "for i, (dist, idx) in enumerate(zip(distances, indices)):\n",
    "    # Filter out the indices where the distance exceeds the adjusted radius\n",
    "    valid_neighbors = idx[dist <= adjusted_radius]\n",
    "\n",
    "    \n",
    "\n",
    "    if len(valid_neighbors) > 0:\n",
    "        try:\n",
    "            # Sum the InitialSaliency for valid neighbors\n",
    "            saliency_sum = eye_metrics.iloc[valid_neighbors]['InitialSaliency'].sum()\n",
    "            mesh_points.at[i, 'SaliencyScore'] = saliency_sum\n",
    "\n",
    "            # Collect labels from valid neighbors\n",
    "            neighbor_labels = eye_metrics.iloc[valid_neighbors]['Labels'].tolist()\n",
    "\n",
    "            # Flatten and collect all labels (since 'Labels' is a set or list for each point)\n",
    "            flat_labels = [label for label_set in neighbor_labels for label in label_set]\n",
    "\n",
    "            # Sum the EEG scores based on label mapping\n",
    "            eeg_sum = sum(label_scores.get(label, 0) for label in flat_labels)\n",
    "            mesh_points.at[i, 'EEGScore'] = eeg_sum\n",
    "\n",
    "            # Append the labels to the 'Labels' column for the current mesh point\n",
    "            mesh_points.at[i, 'Labels'] = flat_labels\n",
    "        except IndexError:\n",
    "            mesh_points.at[i, 'SaliencyScore'] = 0.0\n",
    "            mesh_points.at[i, 'EEGScore'] = 0.0\n",
    "            mesh_points.at[i, 'Labels'] = []\n",
    "    else:\n",
    "        mesh_points.at[i, 'SaliencyScore'] = 0.0\n",
    "        mesh_points.at[i, 'EEGScore'] = 0.0\n",
    "        mesh_points.at[i, 'Labels'] = []\n",
    "#calculate normalised eye saliency \n",
    "min_score, max_score = mesh_points['SaliencyScore'].agg(['min', 'max'])\n",
    "mesh_points['NormalizedScore'] = (mesh_points['SaliencyScore'] - min_score) / (max_score - min_score)\n",
    "# Separate negative and positive values for EEGScore\n",
    "negative_values_eeg = mesh_points['EEGScore'][mesh_points['EEGScore'] < 0]\n",
    "positive_values_eeg = mesh_points['EEGScore'][mesh_points['EEGScore'] > 0]\n",
    "\n",
    "max_negative_eeg = negative_values_eeg.min()  # Most negative value\n",
    "max_positive_eeg = positive_values_eeg.max()  # Most positive value\n",
    "\n",
    "# Normalize EEGScore for values less than 0 by max_negative_eeg (extreme negative)\n",
    "mesh_points['NormalizedEEG'] = mesh_points['EEGScore'].apply(\n",
    "    lambda x: x / abs(max_negative_eeg) if x < 0 else x / max_positive_eeg\n",
    ")\n",
    "\n",
    "# Calculate CombinedScore as the product of SaliencyScore and NormalizedEEG\n",
    "mesh_points['CombinedScore'] = mesh_points['SaliencyScore'] * mesh_points['NormalizedEEG']\n",
    "\n",
    "# Separate negative and positive values for CombinedScore\n",
    "negative_values_combined = mesh_points['CombinedScore'][mesh_points['CombinedScore'] < 0]\n",
    "positive_values_combined = mesh_points['CombinedScore'][mesh_points['CombinedScore'] > 0]\n",
    "\n",
    "# Get the extreme negative and positive values for CombinedScore\n",
    "max_combined_negative = negative_values_combined.min()  # Most negative combined score\n",
    "max_combined_positive = positive_values_combined.max()  # Most positive combined score\n",
    "\n",
    "# Normalize CombinedScore similarly\n",
    "mesh_points['NormalizedCombinedScore'] = mesh_points['CombinedScore'].apply(\n",
    "    lambda x: x / abs(max_combined_negative) if x < 0 else x / max_combined_positive\n",
    ")\n",
    "\n",
    "\n",
    "##########################################################################################################################################################################################################################################################################################\n",
    "mesh_points[['x', 'y', 'z', 'SaliencyScore','NormalizedScore', 'Labels','EEGScore','NormalizedEEG', 'NormalizedCombinedScore']].to_csv('rect15_final_sum_combined_score.csv', index=False)\n",
    "print(\"CSV file 'curved4_score_with_eeg.csv' has been saved.\")\n",
    "########################################################################################################################################################################################################################################################################################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "mesh_points = df2.copy()\n",
    "N = len(mesh_points)\n",
    "\n",
    "alpha = 0.5\n",
    "\n",
    "average_spacing = 1 / np.cbrt(N)\n",
    "\n",
    "mesh_volume = (mesh_points['x'].max() - mesh_points['x'].min()) * \\\n",
    "              (mesh_points['y'].max() - mesh_points['y'].min()) * \\\n",
    "              (mesh_points['z'].max() - mesh_points['z'].min())\n",
    "\n",
    "radius = average_spacing * (alpha ** (1 / 3))\n",
    "adjusted_radius = radius * np.sqrt(mesh_volume / (N * (4 / 3) * np.pi * radius**3))\n",
    "\n",
    "print(f\"Adjusted Radius: {adjusted_radius}\")\n",
    "\n",
    "k = 0.4  # Weight for saliency scores\n",
    "\n",
    "# KDTree preparation for eye points and mesh points\n",
    "eye_points = eye_metrics[['HitPointX', 'HitPointY', 'HitPointZ']].values\n",
    "mesh_points_coords = mesh_points[['x', 'y', 'z']].values\n",
    "eye_tree = cKDTree(eye_points)\n",
    "\n",
    "# Initialize columns\n",
    "mesh_points['SaliencyScore'] = 0.0\n",
    "mesh_points['EEGScore'] = 0.0\n",
    "mesh_points['Labels'] = [[] for _ in range(len(mesh_points))]\n",
    "\n",
    "label_scores = {'Attention': 1, 'Rejection': -1, 'Neutral': 0}\n",
    "\n",
    "# Query the mesh points against the eye hit points (remove distance_upper_bound)\n",
    "distances, indices = eye_tree.query(mesh_points_coords, k=len(eye_points))  # Query all eye points for each mesh point\n",
    "\n",
    "# Process each mesh point to capture the valid neighbors within the adjusted radius\n",
    "for i, (dist, idx) in enumerate(zip(distances, indices)):\n",
    "    valid_neighbors = idx[dist <= adjusted_radius]\n",
    "\n",
    "    if len(valid_neighbors) > 0:\n",
    "        try:\n",
    "            # Sum the InitialSaliency for valid neighbors\n",
    "            saliency_sum = eye_metrics.iloc[valid_neighbors]['InitialSaliency'].sum()\n",
    "            mesh_points.at[i, 'SaliencyScore'] = saliency_sum\n",
    "\n",
    "            # Collect labels from valid neighbors\n",
    "            neighbor_labels = eye_metrics.iloc[valid_neighbors]['Labels'].tolist()\n",
    "\n",
    "            # Flatten and collect all labels (since 'Labels' is a set or list for each point)\n",
    "            flat_labels = [label for label_set in neighbor_labels for label in label_set]\n",
    "\n",
    "            # Sum the EEG scores based on label mapping\n",
    "            eeg_sum = sum(label_scores.get(label, 0) for label in flat_labels)\n",
    "            mesh_points.at[i, 'EEGScore'] = eeg_sum\n",
    "\n",
    "            # Append the labels to the 'Labels' column for the current mesh point\n",
    "            mesh_points.at[i, 'Labels'] = flat_labels\n",
    "        except IndexError:\n",
    "            mesh_points.at[i, 'SaliencyScore'] = 0.0\n",
    "            mesh_points.at[i, 'EEGScore'] = 0.0\n",
    "            mesh_points.at[i, 'Labels'] = []\n",
    "    else:\n",
    "        mesh_points.at[i, 'SaliencyScore'] = 0.0\n",
    "        mesh_points.at[i, 'EEGScore'] = 0.0\n",
    "        mesh_points.at[i, 'Labels'] = []\n",
    "\n",
    "#calculate normalised eye saliency \n",
    "min_score, max_score = mesh_points['SaliencyScore'].agg(['min', 'max'])\n",
    "mesh_points['NormalizedScore'] = (mesh_points['SaliencyScore'] - min_score) / (max_score - min_score)\n",
    "# Separate negative and positive values for EEGScore\n",
    "negative_values_eeg = mesh_points['EEGScore'][mesh_points['EEGScore'] < 0]\n",
    "positive_values_eeg = mesh_points['EEGScore'][mesh_points['EEGScore'] > 0]\n",
    "\n",
    "# Get the extreme negative and positive values for EEGScore\n",
    "max_negative_eeg = negative_values_eeg.min()  # Most negative value\n",
    "max_positive_eeg = positive_values_eeg.max()  # Most positive value\n",
    "\n",
    "# Normalize EEGScore for values less than 0 by max_negative_eeg (extreme negative)\n",
    "mesh_points['NormalizedEEG'] = mesh_points['EEGScore'].apply(\n",
    "    lambda x: x / abs(max_negative_eeg) if x < 0 else x / max_positive_eeg\n",
    ")\n",
    "\n",
    "# Calculate CombinedScore as the product of SaliencyScore and NormalizedEEG\n",
    "mesh_points['CombinedScore'] = mesh_points['SaliencyScore'] * mesh_points['NormalizedEEG']\n",
    "\n",
    "# Separate negative and positive values for CombinedScore\n",
    "negative_values_combined = mesh_points['CombinedScore'][mesh_points['CombinedScore'] < 0]\n",
    "positive_values_combined = mesh_points['CombinedScore'][mesh_points['CombinedScore'] > 0]\n",
    "\n",
    "# Get the extreme negative and positive values for CombinedScore\n",
    "max_combined_negative = negative_values_combined.min()  # Most negative combined score\n",
    "max_combined_positive = positive_values_combined.max()  # Most positive combined score\n",
    "\n",
    "# Normalize CombinedScore similarly\n",
    "mesh_points['NormalizedCombinedScore'] = mesh_points['CombinedScore'].apply(\n",
    "    lambda x: x / abs(max_combined_negative) if x < 0 else x / max_combined_positive\n",
    ")\n",
    "############################################################################################################################################\n",
    "print(mesh_points[['x', 'y', 'z', 'SaliencyScore','NormalizedScore', 'EEGScore', 'NormalizedEEG', 'CombinedScore', 'NormalizedCombinedScore']].head(30))\n",
    "mesh_points[['x', 'y', 'z', 'SaliencyScore','NormalizedScore', 'Labels','EEGScore','NormalizedEEG', 'NormalizedCombinedScore']].to_csv('rect15__combined_mulitply_score.csv', index=False)\n",
    "\n",
    "print(\"CSV file 'curved5_score_with_eeg.csv' has been saved.\")\n",
    "############################################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------END OF PROCESSING --------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6205555,
     "sourceId": 10068519,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6220776,
     "sourceId": 10088852,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6221900,
     "sourceId": 10090306,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6221910,
     "sourceId": 10090317,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6230289,
     "sourceId": 10101231,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6230716,
     "sourceId": 10101796,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6233000,
     "sourceId": 10104880,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6233006,
     "sourceId": 10104887,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6233640,
     "sourceId": 10105711,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6274213,
     "sourceId": 10160868,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6291143,
     "sourceId": 10183864,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
