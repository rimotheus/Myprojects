{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ERrm8gnszOi"
      },
      "source": [
        "This data processing file will **clean raw eye tracking data** and also **compute attention saliency** with the raw eye tracking data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## ensure you install all required depencies\n",
        "!pip install pandas numpy matplotlib scipy plotly"
      ],
      "metadata": {
        "id": "iBP-6Z-xNpHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IECSSIkZ-FiG"
      },
      "source": [
        "This code Removes eye tracking data that are not raycasted on the 3d Object: \"HitObject\" = \"None\"\n",
        "\\\n",
        "and also visualise the cleaned eye tracking data with Point Cloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gutdVTd-cL9Y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib.widgets import CheckButtons\n",
        "\n",
        "## eye tracking data\n",
        "df1 = pd.read_csv(\"/content/eyetrackingdata__rect15.csv\")\n",
        "\n",
        "## mesh data\n",
        "df2 = pd.read_csv(\"/content/rect15_points.csv\")\n",
        "\n",
        "x_min, x_max = df2['x'].min(), df2['x'].max()\n",
        "y_min, y_max = df2['y'].min(), df2['y'].max()\n",
        "z_min, z_max = df2['z'].min(), df2['z'].max()\n",
        "\n",
        "print(\"Mesh Points Boundaries:\")\n",
        "print(f\"X range: [{x_min:.4f}, {x_max:.4f}]\")\n",
        "print(f\"Y range: [{y_min:.4f}, {y_max:.4f}]\")\n",
        "print(f\"Z range: [{z_min:.4f}, {z_max:.4f}]\")\n",
        "\n",
        "## if eye tracking pts not within mesh_pts range --> remove\n",
        "filtered_df1 = df1[\n",
        "    (df1['HitPointX'] >= x_min) & (df1['HitPointX'] <= x_max) &\n",
        "    (df1['HitPointY'] >= y_min) & (df1['HitPointY'] <= y_max) &\n",
        "    (df1['HitPointZ'] >= z_min) & (df1['HitPointZ'] <= z_max) &\n",
        "    (df1['HitObject'] != 'None')\n",
        "\n",
        "]\n",
        "\n",
        "## check how many pts removed\n",
        "print(f\"\\nOriginal raw data points: {len(df1)}\")\n",
        "print(f\"Points after filtering: {len(filtered_df1)}\")\n",
        "print(f\"Mesh points: {len(df2)}\")\n",
        "\n",
        "plt.rcParams['figure.figsize'] = [15, 10]\n",
        "fig = plt.figure()\n",
        "plt.subplots_adjust(left=0.1, bottom=0.1, right=0.95, top=0.95)\n",
        "\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "## eye tracking plot\n",
        "raw_data_plot = ax.scatter(filtered_df1['HitPointX'],\n",
        "                          filtered_df1['HitPointY'],\n",
        "                          filtered_df1['HitPointZ'],\n",
        "                          c='blue', marker='o', label='Raw Data (filtered)',\n",
        "                          alpha=0.6, s=1)\n",
        "\n",
        "## mesh_pts plot\n",
        "mesh_points_plot = ax.scatter(df2['x'], df2['y'], df2['z'],\n",
        "                            c='red', marker='^', label='Mesh points',\n",
        "                            alpha=0.6, s=5)\n",
        "\n",
        "\n",
        "ax.set_xlabel('X')\n",
        "ax.set_ylabel('Y')\n",
        "ax.set_zlabel('Z')\n",
        "ax.set_title('All Points Visualization\\nFiltered Raw Data and Mesh Points')\n",
        "ax.set_axis_off()\n",
        "ax.view_init(elev=20, azim=45)\n",
        "\n",
        "## create option to check/hide mesh pts and/or eye tracking data\n",
        "ax_check = plt.axes([0.02, 0.05, 0.15, 0.10])\n",
        "check = CheckButtons(ax_check, ['Raw Data', 'Mesh Points'],\n",
        "                    [True, True])  # Both visible initially\n",
        "\n",
        "## set visibility\n",
        "def func(label):\n",
        "    if label == 'Raw Data':\n",
        "        raw_data_plot._offsets3d = ([], [], []) if raw_data_plot.get_visible() else (\n",
        "            filtered_df1['HitPointX'],\n",
        "            filtered_df1['HitPointY'],\n",
        "            filtered_df1['HitPointZ'])\n",
        "        raw_data_plot.set_visible(not raw_data_plot.get_visible())\n",
        "    elif label == 'Mesh Points':\n",
        "        mesh_points_plot._offsets3d = ([], [], []) if mesh_points_plot.get_visible() else (\n",
        "            df2['x'], df2['y'], df2['z'])\n",
        "        mesh_points_plot.set_visible(not mesh_points_plot.get_visible())\n",
        "    fig.canvas.draw_idle()\n",
        "\n",
        "check.on_clicked(func)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqEa6wfRcCfp"
      },
      "source": [
        "This code **checks for row duplicates and remove** them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmV3G720rWDN"
      },
      "outputs": [],
      "source": [
        "#filtered d1 is tracking log with timestamp\n",
        "#df2 is mesh points\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.ndimage import gaussian_filter1d\n",
        "\n",
        "eye_data = filtered_df1.copy()\n",
        "eye_data.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Convert datetime format\n",
        "eye_data['Timestamp'] = pd.to_datetime(eye_data['Timestamp'])\n",
        "eye_data = eye_data.sort_values(by='Timestamp')\n",
        "eye_data = eye_data.drop_duplicates(keep='first')\n",
        "\n",
        "# Check for any conversion issues\n",
        "eye_data.reset_index(drop=True, inplace=True)\n",
        "if eye_data['Timestamp'].isnull().any():\n",
        "    print(\"Some timestamps could not be converted. Check the data for invalid formats.\")\n",
        "\n",
        "\n",
        "mesh_data = df2.copy() #creating copy\n",
        "print(eye_data.head(10))\n",
        "print(eye_data.dtypes)\n",
        "print(len(eye_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9DYbGramxSE"
      },
      "outputs": [],
      "source": [
        "## clustering the hit points based on normal HitPointX HitPointY HitPointZ NormalX NormalY NormalZ\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def cluster_eye_data(eye_data, normal_tolerance=0.001):\n",
        "    for i in range(len(eye_data) - 1):\n",
        "        current_row = eye_data[i]\n",
        "        next_row = eye_data[i + 1]\n",
        "\n",
        "        # Check gaze normal difference between current row and next row\n",
        "        normal_diff_next = check_normal_difference(current_row['NormalX'], current_row['NormalY'], current_row['NormalZ'],\n",
        "                                                   next_row['NormalX'], next_row['NormalY'], next_row['NormalZ'],\n",
        "                                                   normal_tolerance)\n",
        "\n",
        "        # If gaze normals are similar, update the current row's hit point\n",
        "        if normal_diff_next:\n",
        "            current_row['HitPointX'] = next_row['HitPointX']\n",
        "            current_row['HitPointY'] = next_row['HitPointY']\n",
        "            current_row['HitPointZ'] = next_row['HitPointZ']\n",
        "\n",
        "    return eye_data\n",
        "\n",
        "\n",
        "def check_normal_difference(normal1_x, normal1_y, normal1_z, normal2_x, normal2_y, normal2_z, tolerance):\n",
        "    # Calculate the difference between the two gaze normals in each component\n",
        "    diff_x = abs(normal1_x - normal2_x)\n",
        "    diff_y = abs(normal1_y - normal2_y)\n",
        "    diff_z = abs(normal1_z - normal2_z)\n",
        "\n",
        "    # If the difference in all components is less than or equal to the tolerance, return True. This helps to cluster the rows to form more concrete data\n",
        "    return diff_x <= tolerance and diff_y <= tolerance and diff_z <= tolerance\n",
        "print(eye_data.head(10))\n",
        "print(eye_data.dtypes)\n",
        "print(len(eye_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdjF8WQlwC8X"
      },
      "outputs": [],
      "source": [
        "## check if time stamp subtraction works\n",
        "import pandas as pd\n",
        "\n",
        "first_row = eye_data.iloc[0]\n",
        "second_row = eye_data.iloc[1]\n",
        "time_diff = (second_row['Timestamp'] - first_row['Timestamp']).total_seconds()\n",
        "\n",
        "print(f\"Time difference between first and second row: {time_diff} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below will compute attention saliency with the 4 eye metrics : Fixation count, Dwell time, Revisit count, Time to First fixation\n",
        "\\\n",
        "It uses a temporary vairable 'CumulativeDwell' to update all saliency scores\n",
        "\\\n",
        "Visited points will be stored in an array to compute the saliency for that given point"
      ],
      "metadata": {
        "id": "KFmqyZyd-Ij0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bQiuVvZthfy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "def calculate_eye_tracking_metrics(data, fixation_threshold=0.1):\n",
        "    metrics_list = []\n",
        "    visited_points = {}\n",
        "    data['InitialSaliency'] = 0\n",
        "\n",
        "    for i, row in data.iterrows():\n",
        "        current_point = (row['HitPointX'], row['HitPointY'], row['HitPointZ'])\n",
        "        timestamp = row['Timestamp']\n",
        "\n",
        "        if current_point not in visited_points:\n",
        "            visited_points[current_point] = {\n",
        "                'FixationCount': 0,\n",
        "                'DwellTime': 0,\n",
        "                'RevisitCount': 0,\n",
        "                'TTFF': None,\n",
        "                'CumulativeDwell': 0,\n",
        "                'FirstFixationTime': None\n",
        "            }\n",
        "\n",
        "        if i < len(data) - 1:\n",
        "            next_row = data.iloc[i + 1]\n",
        "            next_timestamp = next_row['Timestamp']\n",
        "            dwell_time = (next_timestamp - timestamp).total_seconds()\n",
        "\n",
        "            # Accumulate DwellTime for this specific point on every appearance\n",
        "            visited_points[current_point]['DwellTime'] += dwell_time\n",
        "\n",
        "            # Accumulate CumulativeDwell only if the current and next points are the same\n",
        "            next_point = (next_row['HitPointX'], next_row['HitPointY'], next_row['HitPointZ'])\n",
        "            if current_point == next_point:\n",
        "                visited_points[current_point]['CumulativeDwell'] += dwell_time\n",
        "            else:\n",
        "                # Reset CumulativeDwell if the current point does not match the next point\n",
        "                visited_points[current_point]['CumulativeDwell'] = 0\n",
        "\n",
        "        # Time to First Fixation (TTFF) logic: set only the first time the fixation threshold is exceeded\n",
        "        if visited_points[current_point]['FirstFixationTime'] is None and visited_points[current_point]['CumulativeDwell'] >= fixation_threshold:\n",
        "            visited_points[current_point]['FirstFixationTime'] = timestamp\n",
        "            visited_points[current_point]['TTFF'] = (timestamp - data['Timestamp'].min()).total_seconds()\n",
        "\n",
        "        # Fixation Count: Increment each time the cumulative dwell time exceeds the threshold\n",
        "        if visited_points[current_point]['CumulativeDwell'] >= fixation_threshold:\n",
        "            visited_points[current_point]['FixationCount'] += 1\n",
        "            visited_points[current_point]['CumulativeDwell'] = 0  # Reset\n",
        "\n",
        "        # Revisit Count: Increment when the same point appears consecutively in the data\n",
        "        if i > 0:\n",
        "            previous_point = (data.loc[i - 1, 'HitPointX'], data.loc[i - 1, 'HitPointY'], data.loc[i - 1, 'HitPointZ'])\n",
        "            if current_point == previous_point:\n",
        "                visited_points[current_point]['RevisitCount'] += 1\n",
        "\n",
        "    for point, metric in visited_points.items():\n",
        "        metrics_list.append({\n",
        "            'HitPointX': point[0],\n",
        "            'HitPointY': point[1],\n",
        "            'HitPointZ': point[2],\n",
        "            'FixationCount': metric['FixationCount'],\n",
        "            'DwellTime': metric['DwellTime'],\n",
        "            'RevisitCount': metric['RevisitCount'],\n",
        "            'TTFF': metric['TTFF'] if metric['TTFF'] is not None else 0\n",
        "        })\n",
        "\n",
        "    metrics_df = pd.DataFrame(metrics_list)\n",
        "\n",
        "    # Normalize metrics with inverse normalization for TTFF\n",
        "    for col in ['FixationCount', 'DwellTime', 'RevisitCount']:\n",
        "        if metrics_df[col].max() != 0:\n",
        "            metrics_df[col] = metrics_df[col] / metrics_df[col].max()\n",
        "\n",
        "    # Inverse normalization for TTFF: lower TTFF is more salient * different from other eye tracking metrics due to inverse relationship*\n",
        "    if metrics_df['TTFF'].min() != 0:\n",
        "        metrics_df['TTFF'] = 1 - (metrics_df['TTFF'] / metrics_df['TTFF'].max())\n",
        "    else:\n",
        "        metrics_df['TTFF'] = 0\n",
        "\n",
        "    # threshold = 1e-6  # 0.000001 tolerance\n",
        "\n",
        "    metrics_df['InitialSaliency'] = (\n",
        "        0.1 +\n",
        "        0.2 * metrics_df['FixationCount'] +\n",
        "        0.3 * metrics_df['DwellTime'] +\n",
        "        0.2 * metrics_df['RevisitCount'] +\n",
        "        0.2 * metrics_df['TTFF']\n",
        "    )\n",
        "\n",
        "    metrics_df['RevisitCount'] = metrics_df['RevisitCount'].astype(int)\n",
        "\n",
        "    return metrics_df\n",
        "\n",
        "eye_metrics = calculate_eye_tracking_metrics(eye_data)\n",
        "\n",
        "\n",
        "print(eye_metrics[['HitPointX', 'HitPointY', 'HitPointZ', 'FixationCount', 'DwellTime', 'RevisitCount', 'TTFF', 'InitialSaliency']].head(10))\n",
        "print(len(eye_metrics))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below normalizes the saliency score after summation of the individual eye metrics component"
      ],
      "metadata": {
        "id": "ojb_dRqf_k6N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MlscLayN0Zk5"
      },
      "outputs": [],
      "source": [
        "def normalize_saliency_score(data):\n",
        "    \"\"\"\n",
        "    Normalize the InitialSaliency score by dividing it by its maximum value.\n",
        "    The result will be a saliency score between 0 and 1.\n",
        "    \"\"\"\n",
        "    max_saliency = data['InitialSaliency'].max()\n",
        "\n",
        "    if max_saliency != 0:\n",
        "        data['InitialSaliency'] = data['InitialSaliency'] / max_saliency\n",
        "    else:\n",
        "        data['InitialSaliency'] = 0\n",
        "\n",
        "    return data\n",
        "eye_metrics = calculate_eye_tracking_metrics(eye_data)\n",
        "\n",
        "# Normalize the InitialSaliency score\n",
        "eye_metrics = normalize_saliency_score(eye_metrics)\n",
        "\n",
        "print(eye_metrics[['HitPointX', 'HitPointY', 'HitPointZ', 'FixationCount', 'DwellTime', 'RevisitCount', 'TTFF', 'InitialSaliency']].head(10))\n",
        "print(len(eye_metrics))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p101UhGBLakc"
      },
      "outputs": [],
      "source": [
        "print(eye_metrics['InitialSaliency'].min())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyng_FBy84gI"
      },
      "source": [
        "Visualising saliency of hitpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BsM-H4IZG8S4"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import numpy as np\n",
        "\n",
        "eye_metrics_filtered = eye_metrics[eye_metrics['InitialSaliency'] > 0]\n",
        "\n",
        "plt.rcParams['figure.figsize'] = [15, 10]\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "eye_points_plot = ax.scatter(\n",
        "    eye_metrics_filtered['HitPointX'],\n",
        "    eye_metrics_filtered['HitPointY'],\n",
        "    eye_metrics_filtered['HitPointZ'],\n",
        "    c=eye_metrics_filtered['InitialSaliency'],\n",
        "    cmap='viridis',\n",
        "    marker='o',\n",
        "    s=20,\n",
        "    alpha=0.8,\n",
        "    edgecolor='k',\n",
        "    label='Eye-tracking Points'\n",
        ")\n",
        "\n",
        "cbar = plt.colorbar(eye_points_plot, ax=ax, shrink=0.5, aspect=5)\n",
        "cbar.set_label('Saliency Score')\n",
        "\n",
        "ax.set_xlabel('z')\n",
        "ax.set_ylabel('y')\n",
        "ax.set_zlabel('x')\n",
        "ax.set_title('3D Plot of Eye-Tracking Points with Saliency Gradient (Saliency > 0)')\n",
        "\n",
        "ax.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUhNDZ3g_A6c"
      },
      "source": [
        "The use of **scipy.spatial.cKDTree** for a **comutationally efficient algorithmic search** of nearest hitpoints from a pointcloud to **compute the aggregated saliency of that point cloud**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rakgBal69DcR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.spatial import cKDTree\n",
        "\n",
        "mesh_points = df2.copy()\n",
        "N = len(mesh_points)\n",
        "\n",
        "alpha = 0.5\n",
        "\n",
        "average_spacing = 1 / np.cbrt(N)\n",
        "\n",
        "mesh_volume = (mesh_points['x'].max() - mesh_points['x'].min()) * \\\n",
        "              (mesh_points['y'].max() - mesh_points['y'].min()) * \\\n",
        "              (mesh_points['z'].max() - mesh_points['z'].min())\n",
        "\n",
        "radius = average_spacing * (alpha ** (1 / 3)) ## vary alpha for a proportional change in radius\n",
        "adjusted_radius = radius * np.sqrt(mesh_volume / (N * (4 / 3) * np.pi * radius**3)) ## Helps to normalise radius for different kinds of 3d Object dimensions based on average spacings\n",
        "\n",
        "eye_points = eye_metrics[['HitPointX', 'HitPointY', 'HitPointZ']].values\n",
        "mesh_points_coords = mesh_points[['x', 'y', 'z']].values\n",
        "\n",
        "# Create the KDTree for efficient nearest-neighbor search\n",
        "eye_tree = cKDTree(eye_points)\n",
        "\n",
        "mesh_points['SaliencyScore'] = 0.0\n",
        "\n",
        "distances, indices = eye_tree.query(mesh_points_coords, k=len(eye_points))  # Querying all eye points for each point cloud\n",
        "\n",
        "# Print out the indices and distances to inspect\n",
        "print(\"Last index check: \", distances[-1], indices[-1])\n",
        "\n",
        "for i, (dist, idx) in enumerate(zip(distances, indices)):\n",
        "    valid_neighbors = idx[dist <= adjusted_radius]   # Filter out neighbors that are beyond the adjusted radius\n",
        "\n",
        "    if len(valid_neighbors) > 0:  # For valid neighbors\n",
        "        try:\n",
        "            saliency_sum = eye_metrics.iloc[valid_neighbors]['InitialSaliency'].sum() ## Aggregate the InitialSaliency of valid neighbors\n",
        "            mesh_points.at[i, 'SaliencyScore'] = saliency_sum\n",
        "        except IndexError:\n",
        "            print(f\"Error: Invalid indices {valid_neighbors} at mesh point {i}\")\n",
        "            mesh_points.at[i, 'SaliencyScore'] = 0.0\n",
        "    else:\n",
        "        # If no valid neighbors, the saliency score remains 0\n",
        "        mesh_points.at[i, 'SaliencyScore'] = 0.0\n",
        "\n",
        "# Normalize the SaliencyScore\n",
        "min_score, max_score = mesh_points['SaliencyScore'].agg(['min', 'max'])\n",
        "mesh_points['NormalizedScore'] = (mesh_points['SaliencyScore'] - min_score) / (max_score - min_score)\n",
        "\n",
        "print(min_score, max_score)\n",
        "\n",
        "print(mesh_points[['x', 'y', 'z', 'SaliencyScore', 'NormalizedScore']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtU9mAKm2F_8"
      },
      "outputs": [],
      "source": [
        "print(\"Highest SaliencyScore:\", mesh_points['SaliencyScore'].max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyqznJ336c95"
      },
      "outputs": [],
      "source": [
        "##Output file for attention saliency for eye tracking\n",
        "mesh_points[['x', 'y', 'z', 'SaliencyScore', 'NormalizedScore']].to_csv('rect15_score.csv', index=False) ##save the folder\n",
        "\n",
        "print(\"CSV file 'curved1_score.csv' has been saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gC6a7uJa6B54"
      },
      "outputs": [],
      "source": [
        "##visualise the saliency scores\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import numpy as np\n",
        "\n",
        "x = mesh_points['x']\n",
        "y = mesh_points['y']\n",
        "z = mesh_points['z']\n",
        "normalized_scores = mesh_points['NormalizedScore']\n",
        "\n",
        "fig = plt.figure(figsize=(10, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "sc = ax.scatter(x, y, z, c=normalized_scores, cmap='viridis', marker='o')\n",
        "\n",
        "cbar = plt.colorbar(sc, ax=ax)\n",
        "cbar.set_label('Normalized Score')\n",
        "\n",
        "ax.set_xlabel('X')\n",
        "ax.set_ylabel('Y')\n",
        "ax.set_zlabel('Z')\n",
        "\n",
        "ax.set_title('Mesh Points Colored by Normalized Score')\n",
        "\n",
        "# Show the plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-3_h_DjO1AT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "df2 = pd.read_csv(\"/content/rect1_points.csv\")\n",
        "\n",
        "# Number of mesh points\n",
        "N = len(df2)\n",
        "\n",
        "# Define alpha to control the number of mesh points in the spherical AOI\n",
        "alpha = 0.5  # Adjustable\n",
        "\n",
        "average_spacing = 1 / np.cbrt(N)\n",
        "\n",
        "# Calculate the initial radius based on alpha\n",
        "radius = average_spacing * (alpha ** (1 / 3))\n",
        "\n",
        "# Calculate Mesh volume\n",
        "mesh_volume = (df2['x'].max() - df2['x'].min()) * (df2['y'].max() - df2['y'].min()) * (df2['z'].max() - df2['z'].min())\n",
        "\n",
        "\n",
        "adjusted_radius = radius * np.sqrt(mesh_volume / (N * (4 / 3) * np.pi * radius**3))\n",
        "\n",
        "def plot_sphere(ax, center_x, center_y, center_z, radius, color='b', alpha=0.3):\n",
        "    u = np.linspace(0, 2 * np.pi, 100)\n",
        "    v = np.linspace(0, np.pi, 100)\n",
        "    x_sphere = radius * np.outer(np.cos(u), np.sin(v)) + center_x\n",
        "    y_sphere = radius * np.outer(np.sin(u), np.sin(v)) + center_y\n",
        "    z_sphere = radius * np.outer(np.ones(np.size(u)), np.cos(v)) + center_z\n",
        "    ax.plot_surface(x_sphere, y_sphere, z_sphere, color=color, alpha=alpha)\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "ax.scatter(df2['x'], df2['y'], df2['z'], c='gray', marker='.', s=10, alpha=0.5)\n",
        "\n",
        "num_points_to_visualize = 10\n",
        "selected_points = df2.sample(n=num_points_to_visualize)\n",
        "\n",
        "for index, row in selected_points.iterrows():\n",
        "    center_x, center_y, center_z = row['x'], row['y'], row['z']\n",
        "    plot_sphere(ax, center_x, center_y, center_z, adjusted_radius)\n",
        "\n",
        "ax.set_xlabel('X')\n",
        "ax.set_ylabel('Y')\n",
        "ax.set_zlabel('Z')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print(f\"Initial radius: {radius}\")\n",
        "print(f\"Adjusted radius: {adjusted_radius}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8O52gKByuobr"
      },
      "source": [
        "-----------------------------------------------------------END OF PROCESSING ---------------------------------------------------------------------------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANNEX: 3D plot of global processing with radius and ckb tree"
      ],
      "metadata": {
        "id": "yz2GdPEsBrkr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Load mesh data\n",
        "df2 = pd.read_csv(\"/content/rect1_points.csv\")\n",
        "df1 = pd.read_csv(\"/content/eyetrackingdata__rect1.csv\")\n",
        "\n",
        "# Filter eyetracking data\n",
        "x_min, x_max = df2['x'].min(), df2['x'].max()\n",
        "y_min, y_max = df2['y'].min(), df2['y'].max()\n",
        "z_min, z_max = df2['z'].min(), df2['z'].max()\n",
        "\n",
        "filtered_df1 = df1[\n",
        "    (df1['HitPointX'] >= x_min) & (df1['HitPointX'] <= x_max) &\n",
        "    (df1['HitPointY'] >= y_min) & (df1['HitPointY'] <= y_max) &\n",
        "    (df1['HitPointZ'] >= z_min) & (df1['HitPointZ'] <= z_max) &\n",
        "    (df1['HitObject'] != 'None')\n",
        "]\n",
        "\n",
        "# Number of mesh points\n",
        "N = len(df2)\n",
        "\n",
        "alpha = 0.5  # Adjust this value as necessary\n",
        "\n",
        "average_spacing = 1 / np.cbrt(N)\n",
        "\n",
        "radius = average_spacing * (alpha ** (1 / 3))\n",
        "\n",
        "mesh_volume = (df2['x'].max() - df2['x'].min()) * (df2['y'].max() - df2['y'].min()) * (df2['z'].max() - df2['z'].min())\n",
        "\n",
        "adjusted_radius = radius * np.sqrt(mesh_volume / (N * (4 / 3) * np.pi * radius**3))\n",
        "\n",
        "# Plot a translucent sphere\n",
        "def plot_3d_sphere(ax, center_x, center_y, center_z, radius, color='cyan', alpha=0.3):\n",
        "    u = np.linspace(0, 2 * np.pi, 100)\n",
        "    v = np.linspace(0, np.pi, 100)\n",
        "    x_sphere = radius * np.outer(np.cos(u), np.sin(v)) + center_x\n",
        "    y_sphere = radius * np.outer(np.sin(u), np.sin(v)) + center_y\n",
        "    z_sphere = radius * np.outer(np.ones(np.size(u)), np.cos(v)) + center_z\n",
        "    ax.plot_surface(x_sphere, y_sphere, z_sphere, color=color, alpha=alpha, edgecolor='none')\n",
        "\n",
        "fig = plt.figure(figsize=(12, 10))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.scatter(df2['x'], df2['y'], df2['z'], c='gray', marker='o', s=5, alpha=0.3, label='Point Cloud')\n",
        "ax.scatter(filtered_df1['HitPointX'], filtered_df1['HitPointY'], filtered_df1['HitPointZ'], c='red', marker='o', s=2, alpha=0.6, label='Eyetracking Points')\n",
        "\n",
        "# Select a subset of mesh points for sphere visualization\n",
        "num_points_to_visualize = 30\n",
        "selected_points = df2.sample(n=num_points_to_visualize)\n",
        "for _, row in selected_points.iterrows():\n",
        "    center_x, center_y, center_z = row['x'], row['y'], row['z']\n",
        "    plot_3d_sphere(ax, center_x, center_y, center_z, adjusted_radius)\n",
        "\n",
        "ax.set_box_aspect([1, 1, 1])\n",
        "ax.grid(False)\n",
        "ax.set_axis_off()\n",
        "ax.set_title('3D Visualization of Radius Around Mesh Points', fontsize=16)\n",
        "\n",
        "# Add legend\n",
        "ax.legend(loc='upper right')\n",
        "\n",
        "# Improve depth perception\n",
        "ax.view_init(elev=30, azim=120)  # Adjust viewing angle\n",
        "ax.dist = 5  # Adjust camera distance for better perception\n",
        "\n",
        "plt.show()\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter3d(\n",
        "    x=df2['x'], y=df2['y'], z=df2['z'],\n",
        "    mode='markers',\n",
        "    marker=dict(size=2, color='gray', opacity=0.3),\n",
        "    name='Mesh Points'\n",
        "))\n",
        "\n",
        "# Add eyetracking points\n",
        "fig.add_trace(go.Scatter3d(\n",
        "    x=filtered_df1['HitPointX'], y=filtered_df1['HitPointY'], z=filtered_df1['HitPointZ'],\n",
        "    mode='markers',\n",
        "    marker=dict(size=2, color='red', opacity=0.7),\n",
        "    name='Eyetracking Points'\n",
        "))\n",
        "\n",
        "# Add spheres\n",
        "for _, row in selected_points.iterrows():\n",
        "    center_x, center_y, center_z = row['x'], row['y'], row['z']\n",
        "    u = np.linspace(0, 2 * np.pi, 100)\n",
        "    v = np.linspace(0, np.pi, 100)\n",
        "    x_sphere = adjusted_radius * np.outer(np.cos(u), np.sin(v)) + center_x\n",
        "    y_sphere = adjusted_radius * np.outer(np.sin(u), np.sin(v)) + center_y\n",
        "    z_sphere = adjusted_radius * np.outer(np.ones(np.size(u)), np.cos(v)) + center_z\n",
        "    fig.add_trace(go.Surface(\n",
        "        x=x_sphere, y=y_sphere, z=z_sphere,\n",
        "        opacity=0.3, colorscale='Blues', showscale=False\n",
        "    ))\n",
        "\n",
        "fig.update_layout(scene=dict(aspectmode='data'), title='Interactive 3D Visualization')\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "qoLbNFRsEUjs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}